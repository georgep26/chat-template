run: # Configuration for a particular evaluation run
  evaluation_run_name: "nova_micro_pr_eval"
  max_concurrent_async_tasks: 20
  persist_rag_outputs: true

rag_app:
  # local_entrypoint: "src.rag_lambda.main:main"
  lambda_function_name: "chat-template-staging-rag-chat" # uncomment this if you want to run the evaluation on a lambda function


data:
  eval_csv_path: "evals/validation_data/human_generated_validation_questions.csv"
  eval_id_column: "validation_question_id"
  eval_question_column: "validation_question"
  eval_reference_column: "answer"
  eval_citation_column: "citation"
  eval_source_column: "source"
  eval_human_validated_column: "human_validated"
  # optional extra columns auto-loaded into metadata

metrics:
  ragas:
    enabled: true
    metric_names: ["faithfulness", "answer_relevancy", "context_precision", "context_recall"]
    judge_model:
      provider: "bedrock" # E.g. "openai" or "bedrock"
      model: "amazon.nova-micro-v1:0"  
      region_name: "us-east-1"
    # embedding_model: Optional. If not provided, defaults to OpenAI embeddings.
    # This should be explicitly configured to match your judge_model provider.
    embedding_model:
      provider: "bedrock"  # "bedrock" or "openai". If omitted, defaults to "openai"
      model: "amazon.titan-embed-text-v2:0"  # For Bedrock: "amazon.titan-embed-text-v2:0" or "amazon.titan-embed-text-v1:0"
      region_name: "us-east-1"  # Required for Bedrock
      # For OpenAI, you can optionally specify:
      # openai_api_key_env: "OPENAI_API_KEY"  # Environment variable name for API key
  binary_correctness:
    enabled: true
    judge_model:
      provider: "bedrock"  # E.g. "openai" or "bedrock"
      model: "amazon.nova-micro-v1:0"  
      region_name: "us-east-1"
  atomic_correctness:
    enabled: true
    judge_model:
      provider: "bedrock"
      model: "amazon.nova-micro-v1:0"
      region_name: "us-east-1"
  context_relevance:
    enabled: false
    judge_model:
      provider: "bedrock"
      model: "amazon.nova-micro-v1:0"
      region_name: "us-east-1"

llm:
  default:
    provider: "bedrock"            # "openai" or "bedrock"
    model: "amazon.nova-micro-v1:0"
    region_name: "us-east-1"

outputs:
  types: ["html", "json", "csv"]  # CLI can override
  local:
    base_dir: "evals/eval_outputs"
  s3:
    enabled: false
    s3_uri: "s3://my-eval-bucket/rag-evals/irc/"
    # Uploads are base_dir/experiment_name/{files} -> s3_uri/experiment_name/...

