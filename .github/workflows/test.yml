name: Tests

on:
  workflow_dispatch:
  workflow_call:

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      checks: write
      pull-requests: write
      contents: read
    strategy:
      matrix:
        python-version: ["3.11"]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          environment-file: environment.yml
          activate-environment: chat-template-env
          python-version: ${{ matrix.python-version }}
          auto-activate-base: false

      - name: Install additional test dependencies
        shell: bash -l {0}
        run: |
          pip install pytest-html pytest-xdist

      - name: Set PYTHONPATH
        shell: bash -l {0}
        run: |
          echo "PYTHONPATH=${{ github.workspace }}/src:$PYTHONPATH" >> $GITHUB_ENV

      - name: Create test results directory
        shell: bash -l {0}
        run: mkdir -p junit

      - name: Run tests
        id: pytest
        continue-on-error: true
        shell: bash -l {0}
        env:
          PYTHONPATH: ${{ github.workspace }}/src:${{ env.PYTHONPATH }}
        run: |
          pytest tests/ \
            --junitxml=junit/test-results.xml \
            --html=test-report.html \
            --self-contained-html \
            -v

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: junit/test-results.xml
          check_name: "Test Results"
          comment_mode: always
          report_individual_runs: true
          deduplicate_classes_by_file_name: true
          test_changes_limit: 50
          check_run_annotations: "all tests"
          job_summary: true

      - name: Parse test results and create detailed comment
        if: always() && github.event_name == 'pull_request'
        shell: bash -l {0}
        run: |
          python << 'EOF'
          import xml.etree.ElementTree as ET
          import json
          
          # Parse JUnit XML
          tree = ET.parse('junit/test-results.xml')
          root = tree.getroot()
          
          # Collect all test cases
          test_cases = []
          total_tests = 0
          total_failures = 0
          total_errors = 0
          total_time = 0.0
          
          for testsuite in root.findall('testsuite'):
              total_tests += int(testsuite.get('tests', 0))
              total_failures += int(testsuite.get('failures', 0))
              total_errors += int(testsuite.get('errors', 0))
              total_time += float(testsuite.get('time', 0))
              
              for testcase in testsuite.findall('testcase'):
                  name = testcase.get('name', 'Unknown')
                  classname = testcase.get('classname', '')
                  time = testcase.get('time', '0')
                  
                  status = 'âœ… Passed'
                  message = ''
                  if testcase.find('failure') is not None:
                      status = 'âŒ Failed'
                      failure = testcase.find('failure')
                      message = failure.get('message', '') or (failure.text[:500] if failure.text else '')
                  elif testcase.find('error') is not None:
                      status = 'âš ï¸ Error'
                      error = testcase.find('error')
                      message = error.get('message', '') or (error.text[:500] if error.text else '')
                  elif testcase.find('skipped') is not None:
                      status = 'â­ï¸ Skipped'
                  
                  test_cases.append({
                      'name': name,
                      'classname': classname,
                      'status': status,
                      'time': time,
                      'message': message
                  })
          
          # Build markdown comment
          passed = total_tests - total_failures - total_errors
          comment = '## ðŸ“Š Detailed Test Results\n\n'
          comment += f'**Total Tests:** {total_tests} | '
          comment += f'**Passed:** {passed} | '
          comment += f'**Failed:** {total_failures} | '
          comment += f'**Errors:** {total_errors} | '
          comment += f'**Duration:** {total_time:.2f}s\n\n'
          
          if test_cases:
              comment += '| Test Name | Status | Duration |\n'
              comment += '|-----------|--------|----------|\n'
              
              for tc in test_cases:
                  test_name = tc['name']
                  if tc['classname']:
                      test_name = f"{tc['classname']}::{tc['name']}"
                  comment += f"| `{test_name}` | {tc['status']} | {tc['time']}s |\n"
              
              # Add failure details if any
              failures = [tc for tc in test_cases if 'âŒ' in tc['status'] or 'âš ï¸' in tc['status']]
              if failures:
                  comment += '\n### âŒ Failed/Error Details\n\n'
                  for tc in failures:
                      test_name = tc['name']
                      if tc['classname']:
                          test_name = f"{tc['classname']}::{tc['name']}"
                      comment += f"**{test_name}**\n"
                      if tc['message']:
                          comment += f"```\n{tc['message']}\n```\n\n"
          else:
              comment += 'No test cases found in the results.\n'
          
          # Write comment to file for next step
          with open('test-comment.md', 'w') as f:
              f.write(comment)
          EOF

      - name: Post detailed test results comment
        if: always() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comment = fs.readFileSync('test-comment.md', 'utf8');
            
            const prNumber = context.payload.pull_request?.number;
            if (prNumber) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body: comment
              });
            }

      - name: Upload test report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-report-${{ matrix.python-version }}
          path: test-report.html
          retention-days: 30

      - name: Check test results
        if: steps.pytest.outcome != 'success'
        shell: bash -l {0}
        run: |
          echo "Tests failed. Check the test results above."
          exit 1

