name: Run Evaluations

on:
  pull_request:
    branches:
      - main
    paths:
      - 'evals/**'
      - 'src/**'
      - 'data/**'
      - 'evals/evals_config.yaml'
      - '.github/workflows/run-evals.yml'

jobs:
  run-evals:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check if PR is from development branch
        id: check-branch
        run: |
          PR_BRANCH="${{ github.head_ref }}"
          if [ "$PR_BRANCH" != "development" ]; then
            echo "PR is from branch '$PR_BRANCH', not 'development'. Skipping evaluation."
            echo "skip=true" >> $GITHUB_OUTPUT
            exit 0
          else
            echo "PR is from 'development' branch. Running evaluation."
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Set up Miniconda
        if: steps.check-branch.outputs.skip != 'true'
        uses: conda-incubator/setup-miniconda@v3
        with:
          auto-update-conda: true
          python-version: '3.11'
          environment-file: environment.yml
          activate-environment: chat-template-env

      - name: Verify conda environment
        if: steps.check-branch.outputs.skip != 'true'
        shell: bash -l {0}
        run: |
          conda info
          conda list

      - name: Configure AWS credentials
        if: steps.check-branch.outputs.skip != 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-east-1
        env:
          AWS_REGION: us-east-1

      - name: Set PYTHONPATH
        if: steps.check-branch.outputs.skip != 'true'
        shell: bash -l {0}
        run: |
          echo "PYTHONPATH=${{ github.workspace }}" >> $GITHUB_ENV

      - name: Run evaluation pipeline
        if: steps.check-branch.outputs.skip != 'true'
        shell: bash -l {0}
        run: |
          python evals/evals_pipeline.py --config evals/evals_config.yaml

      - name: Upload evaluation results
        if: steps.check-branch.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: eval-results
          path: evals/eval_outputs/
          retention-days: 7

